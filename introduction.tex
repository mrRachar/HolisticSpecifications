Software guards our secrets, our money, our intellectual property,
our reputation \cite{covfefe}.  We entrust personal and
corporate information to software which works in an \emph{open} world, 
where  it interacts with a vast number of
third party software of unknown provenance, possibly buggy and potentially malicious.

Thus, we expect and hope that our software will be \emph{robust}:
We expect and hope our software to behave correctly even if  used 
by erroneous or malicious third parties. Robustness means 
something different for each different software.
 We expect, \eg, that our bank will only make payments 
from our account if instructed by us or somebody authorized CITE-ERC20,
that  space on a web given to an advertiser will not be used
to obtain access to our bank details ... CITE-SOME-DOM-HORROR.

The importance of robustness has lead to the design of many programming
language mechanisms which help write robust programs:
constant fields or methods \cite{...}, private methods/fields\cite{...}, ownerschip\cite{...}
as well as the object capability paradigm\cite{millerPhDThesis},
and its adoption in recent programming languages and web systems
\cite{CapJavaHayesAPLAS17,CapNetSocc17Eide,DOCaT14} including Newspeak
\cite{newspeak17}, Dart \cite{dart15}, Grace \cite{grace,graceClasses}
and Wyvern \cite{wyverncapabilities}

While such programming language mechanisms make it \textit{possible} to write robust
programs, they cannot \textit{ensure} that programs are robust. 
To be able to do this, we need ways to specify what robustness means for the 
particular program, and ways to demonstrate that the particular program 
adheres to its specific robustness requirements.

There has been a plethora of work on the functional specification and verification of the
functional correctness of programs. Such specification describe what are
essentially \emph{sufficient} conditions for some
effect to happen. For example, if you make a payment request to your bank, money will be transfered
and as a result your funds will be reduced: the payment request is a sufficient condition for the
reduction of funds. However, a bank client is also interested in \emph{necessary} conditions:
they want to be assured that no reduction in their funds will take place unless they themselves
requested it.

Necessary conditions are essentially about things that will {\em not} happen. For example,
there  will be no reduction to the account's funds without the owner's explicit request, and
the top layers of the DOM tree cannot be reached by the ad-provider.


One may take the view that the necessary conditions are not more than the complement of all the sufficient conditions.
In other words, the possible behaviours of a module is the union of all possible behaviours of 
each individual function, and the necessary conditions is their complement,
We describe this in the left hand side of the diagram in Figure \ref{fig:NecessaryAndSuff}: we 
represent the space of all theoretically possible behaviours as points in the rectangle, 
each function is a coloured oval and its possible behaviours are the points in the area of the oval.   
Then, the necessary conditions are all the points  outside the ovals.  

This view is mathematically sound but it is impractical,  brittle wrt software maintenance, and weak wrt the open
world setting.

It is impractical, because suggests that the client interested in a necessity guarantee 
would only need to read the specifications of all the functions  in a module so as to extract their complement.
This could be a huge task in view of the number of these functions, and also 
in view of the possible emergent behaviours. What if the bank did indeed enforce that only the account
owner may withdraw funds, but had another function which allowed the manager
to appoint an account supervisor, and another which allowed the account supervisor to
assign owners?

It is brittle wrt software maintenance, because it
 gives no guidance to the team maintaining a piece of software: if the 
necessary conditions which were implicitly in the developers' intentions are not explicitly 
described, subsequent developers may inadvertedly add functions which break these intentions.

It is weak wrt the open world because if does not .... talk here about passing my stuff to unknowns objects.

We propose that necessary conditions should be explicitly stated as in the middle of our diagram. 
A full specification of  a module consists of both the sufficient as well as the necessary conditions, as in the
right hand side of the diagram. 

  \begin{figure}[htb]
 \begin{tabular}{ccccc}
\begin{minipage}{0.25\textwidth}
 \includegraphics[width=\linewidth, trim=250  320 260 60,clip]{diagrams/Suff.pdf}
\end{minipage}
 & & 
\begin{minipage}{0.25\textwidth}
 \includegraphics[width=\linewidth, trim=250  320 260 60,clip]{diagrams/Nec.pdf}
\end{minipage}
 & &
\begin{minipage}{0.25\textwidth}
 \includegraphics[width=\linewidth, trim=250  320 260 60,clip]{diagrams/NecAndSuff.pdf}
\end{minipage}
\\
sufficient & & necessary & & together
%\begin{minipage}{0.75\textwidth}
%\includegraphics[width=\linewidth, trim=145  320 60 105,clip]{diagrams/NecAndSuff.pdf}
%\end{minipage}
%% y seems to eat up the bollom
%% x eats space from left, if you increase it the diagram decreases from left
%% w eats space from top, if you increase it the diagram decreases from top
%%\includegraphics[page=3, width=\linewidth, trim=150  270 40 150, clip]{diagrams/snmalloc.pdf}\sdcomment{I think we need to change the diagram so that it says small slab.}
%\end{minipage}
 \end{tabular}
  \vspace*{-4.5mm}
  \caption{Sufficient and Necessary Conditions}
 \label{fig:NecessaryAndSuff}
 \end{figure}

... say that this is about invariants

... say that invariants are long known and used: eg type systems and and information flow control (comoare) and also
object invariants

... compare with obj invariants - they are about state properties, ours add space/time/control.

... outline the ingredients of Chainmail

... outline the open world



... contributions

 
%However what has been less well-studied
%so far, is the characterization of the ways in which a system is robust, \ie how do we
%specify robustness. What exactly do we expect from a module in 
%
% 
%The traditional (philosophically, the ``modern'' approach) to
%construct secure systems is to build up trusted components as an
%hierarchy on top of a known and trusted secured computing base,
%underpinned by verified and verifying compilers \cite{HoareManifesto}.
%This approach relies on a closed world assumption: there is an
%explicitly demarcated border between the inside and the outside of the
%system, and the whole system can be trusted because (and as long as)
%each component inside the border can be trusted. Similarly, each
%module is an independent demesnes \cite{wills}, jealously
%protecting its own invariants behind its own borders, giving rise to a
%series of layers of trust, layered virtual machines
%\cite{nosp} or protection rings \cite{pola}.
%
%Open
%systems, on the other hand, have an open world assumption: they must
%interact with a wide range of component objects with different levels
%of mutual trust (or distrust) --- and whose configuration dynamically
%changes.
%%
%% Consider electronic payments systems such as Swift, Paypal,
%% or WeSwap.com: they must transfer funds between participants'
%% accounts, where the participants do not trust each other, cannot be
%% trusted by the payments system, and may join or leave the system at
%% any time.  With multiple competing payments systems across different
%% international juristidctions, there is no central authority that can
%% vouch for the trusworthiness of participants or payments systems.
%%
%Given a method request \lstinline+x.m(y)+, what can
%we conclude about the behaviour of this request if we know nothing
%about the receiver \lstinline+x+?
% 
%
%The critical
%problem with building systems for an open world is that the actual
%invariants that must be maintained by a program will be
%\textit{implicit}, scattered throughout the program's modules.  Any
%part of a program that uses an object from a trusted module may (by
%oversight, error, or fraud) hand that object to an untrustworthy
%module, giving potentially malicious code access to all the services
%provided by the trustworthy module \cite{geneva91,aliasingBook}.  This
%makes it hard to determine what invariants are actually maintained by
%a given module, and thus verify the integrity of the overall system.
%%
%Miller \cite{miller-esop2013,MillerPhD} defines the necessary approach
%as \textbf{defensive consistency}: \textit{``An object is defensively
%  consistent when it can defend its own invariants and provide correct
%  service to its well behaved clients, despite arbitrary or malicious
%  misbehaviour by its other clients.''}  Defensively consistent
%modules are particularly hard to design, to write, to understand, and
%to verify: but they have the great advantage that they make it much
%easier to make guarantees about systems composed of multiple components
%\cite{Murray:phd}.
%
%
%In this paper, we present a modular specification language,
%\Chainmail, that is designed to support defensively consistent
%specifications of these kinds of open
%systems. Building on the object-capability model \cite{Elang},
%\Chainmail\ specifications are modular, as separate concerns in a
%system can be captured in as individual specification or policy
%definitions.  \Chainmail\ specifications 
%not tied to any particular module in a system but can define
%the behaviour of any complying module, and can cross-cut multiple
%modules.  \Chainmail\ policies define not only method pre- and post-
%conditions, but also give invariants that must be maintained
%\emph{irrespective} of any other code in the system, even when the
%actual composition of the system is unknown.  Taken together, this
%means that \Chainmail\ can specify modules that must be
%\emph{defensively consistent}, guaranteeing their integrity in an
%arbitrary open world.
%  
% 
%%\kjx{need to say what the case studies are.   or not!}
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% TO HERE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%\paragraph{Contribution} 
%This paper extends earlier informal work mostly presented at
%workshops~\cite{capeFTfJP,capeFTfJP14,swapsiesOnTheInternet2015,capeIFM14}.
%Here we present the full design of \Chainmail\ for the first time, and
%show how \Chainmail\ allows us to write modular, multi-dimensional
%specifications for the open world.  As is traditional, some details
%are relegated to a technical report~\cite{appendix}.
%
%To address the open nature of the systems, we make the meaning of
%policies parametric with any code that may be linked to the
%current system.  We give examples to show how \Chainmail\ modules can
%be written in a very robust, defensively consistent manner, so that no
%further, malicious code can steal their secrets or break their
%integrity.
%
%% This has let us give a
%% formal meaning to Miller's \emph{defensive consistency} for the first
%% time. \tobym{Not quite true. I had a stab at defining defensive correctness
%% and consistency in my PhD thesis, which I've summarised in \autoref{sec:related}.}
%
%Our design of \Chainmail\ is part of a larger research project about
%specifying and verifying systems in an open world.  Security is of
%particular concern in open systems, and \Chainmail\ includes
%assertions such as (\obeys, \MayAffect, and \MayAccess) to allow
%us to reason explicitly about module's security properties and
%guarantees.  Elsewhere we demonstrate how these constructs let us
%describe how components can co{\"o}perate to establish trust
%gradually, and to delineate the risks involved in that co{\"o}peration
%\cite{POSTSUBMITTED}. Security, trust, and risk are not the focus of
%this paper, rather here we concentrate on the core features of
%\Chainmail, showing how \Chainmail\ policies permit modular,
%defensively consistent specifications.
%
%To give a semantics to \Chainmail\ policies we have also defined a
%core object-oriented programming language, \LangOO, (the Featherweight
%Object Capability Language, not to be confused with FOCAL
%\cite{FOCAL-69}), described in more detail elsewhere \cite{appendix}.
%\LangOO\ is a simple, dynamically typed language with traditional
%classes as its modularly mechanism.  That is, \Chainmail\ provides
%separation of concerns for \emph{specifications} of object-oriented
%\emph{implementations}.  We made this design choice for several
%reasons, primarily because we are interested in specifications, rather
%than implementations.  We are primarily
%interested in specifying ``real world'' programs, which tend to be
%written in OO languages like JavaScript, Java or E, rather than e.g.\
%aspect- or subject- oriented languages; and that we wanted to keep
%\LangOO\ as simple as possible.  We hope to extend our specification
%techniques to more modular languages in future work.
%
%To prove a program's adherence to \Chainmail\ specifications, we have
%developed a Hoare logic and associated inference rules.  We do not
%discuss the logic or these rules in this paper, although they are
%present in the technical report \cite{appendix}.
 
